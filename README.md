# ğŸš€ GitHub Issues Prediction Pipeline

[![Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.5-231F20?logo=apachekafka&logoColor=white)](https://kafka.apache.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-7.0-47A248?logo=mongodb&logoColor=white)](https://www.mongodb.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.10-0194E2?logo=mlflow&logoColor=white)](https://mlflow.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)

> **Pipeline Big Data temps rÃ©el** pour la collecte, le traitement et la prÃ©diction du temps de rÃ©solution des issues GitHub.

---

## ğŸ“‹ Table des MatiÃ¨res

- [Architecture](#-architecture)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [PrÃ©requis](#-prÃ©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Services](#-services)
- [Machine Learning](#-machine-learning)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)
- [Contributeurs](#-contributeurs)

---

## ğŸ— Architecture

```mermaid
graph LR
    A[GitHub API] -->|REST| B(Kafka Producer)
    B -->|Push| C{Apache Kafka}
    C -->|Stream| D[Spark Streaming]
    D -->|Clean & Process| E[(MongoDB)]
    E -->|Read| F[Dashboard Streamlit]
    G[ML Models] -->|Predict| F
    G <-->|Track| H[MLflow]
```

### Flux de DonnÃ©es

1. **Collecte** : Le collecteur Python interroge l'API GitHub pour rÃ©cupÃ©rer les issues.
2. **Ingestion** : Les donnÃ©es sont envoyÃ©es vers Kafka (topic: `github.issues.raw`).
3. **Traitement** : Spark Structured Streaming consomme, nettoie et enrichit les donnÃ©es.
4. **Stockage** : Les donnÃ©es traitÃ©es sont persistÃ©es dans MongoDB (upsert).
5. **PrÃ©diction** : Les modÃ¨les ML prÃ©disent le temps de rÃ©solution des issues.
6. **Visualisation** : Dashboard Streamlit pour l'analyse et le monitoring.

---

## âœ¨ FonctionnalitÃ©s

- âœ… Collecte temps rÃ©el des issues GitHub via API REST
- âœ… Streaming avec Kafka pour l'ingestion haute performance
- âœ… Traitement Spark avec nettoyage et dÃ©duplication
- âœ… Stockage MongoDB avec upsert (pas de doublons)
- âœ… ModÃ¨les ML pour prÃ©dire le temps de rÃ©solution
- âœ… MLflow pour le tracking des expÃ©riences
- âœ… Dashboard interactif avec Streamlit
- âœ… Architecture Docker entiÃ¨rement conteneurisÃ©e

---

## ğŸ“¦ PrÃ©requis

- Docker >= 24.0
- Docker Compose >= 2.20
- Git >= 2.40
- GitHub Personal Access Token (pour l'API GitHub)

### Ressources recommandÃ©es

| Ressource | Minimum | RecommandÃ© |
|-----------|---------|------------|
| RAM       | 8 GB    | 16 GB      |
| CPU       | 4 cores | 8 cores    |
| Disque    | 20 GB   | 50 GB      |

---

## ğŸ›  Installation

### 1. Cloner le repository

```bash
git clone https://github.com/your-username/github-issues-prediction-pipeline.git
cd github-issues-prediction-pipeline
```

### 2. Configurer les variables d'environnement

Copiez le fichier d'exemple et configurez vos clÃ©s :

```bash
cp .env.example .env
```

Ã‰ditez le fichier `.env` :

```ini
# GitHub API
GITHUB_TOKEN=ghp_your_personal_access_token

# MongoDB
MONGO_INITDB_ROOT_USERNAME=root
MONGO_INITDB_ROOT_PASSWORD=rootpassword
MONGODB_URI=mongodb://root:rootpassword@mongodb:27017/

# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# MLflow
MLFLOW_TRACKING_URI=http://mlflow:5001
```

### 3. Lancer l'infrastructure

```bash
# DÃ©marrer tous les services
docker compose up -d

# VÃ©rifier que tous les services sont running
docker compose ps
```

### 4. Initialiser Kafka topics

```bash
docker exec -it kafka kafka-topics --create \
  --topic github.issues.raw \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1
```

---

## ğŸš€ Utilisation

### DÃ©marrer le pipeline complet

1. **Lancer l'infrastructure** (si ce n'est pas dÃ©jÃ  fait) :

```bash
docker compose up -d
```

2. **DÃ©marrer le job Spark Streaming** :

```bash
./spark/submit.sh
```

3. **Lancer le collecteur GitHub** :

```bash
docker compose up -d kafka-producer
```

4. **AccÃ©der au dashboard** : Ouvrez http://localhost:8501

### Commandes utiles

```bash
# Voir les logs en temps rÃ©el
docker compose logs -f spark-master

# ArrÃªter tous les services
docker compose down

# Reconstruire les images
docker compose up -d --build

# VÃ©rifier l'Ã©tat de Kafka
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

---

## ğŸ“ Structure du Projet

```
github-issues-prediction-pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ ğŸ“„ .env                        # Variables d'environnement
â”œâ”€â”€ ğŸ“„ requirements.txt            # DÃ©pendances Python globales
â”‚
â”œâ”€â”€ ğŸ“‚ Data_Collector/             # Module de collecte GitHub
â”‚   â”œâ”€â”€ github_collector/          # Client API GitHub
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ github_client.py       # Client HTTP GitHub
â”‚   â”‚   â”œâ”€â”€ issues.py              # Collecte des issues
â”‚   â”‚   â””â”€â”€ state.py               # Gestion de l'Ã©tat
â”‚   â”œâ”€â”€ config.json                # Configuration des repos
â”‚   â”œâ”€â”€ run_collector.py           # Point d'entrÃ©e collecteur
â”‚   â””â”€â”€ collect_issues.sh          # Script shell de collecte
â”‚
â”œâ”€â”€ ğŸ“‚ github_bigdata_pipeline/    # Pipeline Kafka
â”‚   â””â”€â”€ collector/
â”‚       â”œâ”€â”€ kafka_producer.py      # Producteur Kafka
â”‚       â””â”€â”€ run_collector_kafka.py # Collecteur â†’ Kafka
â”‚
â”œâ”€â”€ ğŸ“‚ spark/                      # Jobs Spark
â”‚   â”œâ”€â”€ process_stream.py          # Spark Structured Streaming
â”‚   â”œâ”€â”€ submit.sh                  # Script de soumission
â”‚   â””â”€â”€ requirements.txt           # DÃ©pendances Spark
â”‚
â”œâ”€â”€ ğŸ“‚ ml/                         # Machine Learning
â”‚   â”œâ”€â”€ train_model.py             # EntraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ predict.py                 # PrÃ©dictions
â”‚   â””â”€â”€ feature_engineering.py     # CrÃ©ation de features
â”‚
â”œâ”€â”€ ğŸ“‚ dashboard/                  # Interface utilisateur
â”‚   â”œâ”€â”€ app.py                     # Dashboard principal
â”‚   â”œâ”€â”€ train_viz.py               # Visualisation donnÃ©es training
â”‚   â”œâ”€â”€ Dockerfile                 # Image Docker Streamlit
â”‚   â””â”€â”€ requirements.txt           # DÃ©pendances dashboard
â”‚
â”œâ”€â”€ ğŸ“‚ mongo/                      # Configuration MongoDB
â”‚   â””â”€â”€ init.js                    # Scripts d'initialisation
â”‚
â”œâ”€â”€ ğŸ“‚ data/                       # DonnÃ©es locales
â”‚   â””â”€â”€ state/                     # Ã‰tat du collecteur
â”‚
â”œâ”€â”€ ğŸ“‚ mlflow-data/                # Artefacts MLflow
â””â”€â”€ ğŸ“‚ mlflow-db/                  # Base de donnÃ©es MLflow
```

---

## ğŸ³ Services

| Service      | Port  | Description        | URL                      |
|--------------|-------|--------------------|--------------------------|
| Kafka        | 9092  | Message broker     | `localhost:9092`         |
| Zookeeper    | 2181  | Coordination Kafka | `localhost:2181`         |
| MongoDB      | 27017 | Base de donnÃ©es    | `localhost:27017`        |
| Spark Master | 8080  | Cluster manager    | http://localhost:8080    |
| Spark Worker | 8081  | Worker node        | http://localhost:8081    |
| MLflow       | 5001  | Tracking server    | http://localhost:5001    |
| Dashboard    | 8501  | App principale     | http://localhost:8501    |
| Train Viz    | 8502  | Visualisation training | http://localhost:8502 |
| Kafka UI     | 8082  | Interface Kafka    | http://localhost:8082    |

---

## ğŸ¤– Machine Learning

### ModÃ¨les disponibles

| ModÃ¨le           | Description                    | MÃ©trique |
|------------------|--------------------------------|----------|
| RandomForest     | Classification temps rÃ©solution | F1-Score |
| XGBoost          | Gradient boosting              | RMSE     |
| LinearRegression | Baseline rÃ©gression            | MAE      |

### Features utilisÃ©es

```python
features = [
    'title_length',        # Longueur du titre
    'body_length',         # Longueur du corps
    'labels_count',        # Nombre de labels
    'comments_count',      # Nombre de commentaires
    'has_assignee',        # PrÃ©sence d'assignÃ©
    'is_bug',              # Label "bug" prÃ©sent
    'is_enhancement',      # Label "enhancement" prÃ©sent
    'hour_of_day',         # Heure de crÃ©ation
    'day_of_week',         # Jour de la semaine
]
```

### EntraÃ®ner un modÃ¨le

**Via Docker :**

```bash
docker exec -it dashboard python -m ml.train_model
```

**Localement :**

```bash
python ml/train_model.py --experiment-name "github-issues-v1"
```

### Tracking avec MLflow

AccÃ©dez Ã  http://localhost:5001 pour :

- Comparer les runs
- Visualiser les mÃ©triques
- TÃ©lÃ©charger les artefacts
- DÃ©ployer les modÃ¨les

---

## ğŸ“Š Monitoring

### Spark UI

- **Master UI** : http://localhost:8080
- **Job UI** : http://localhost:4040 (disponible uniquement pendant l'exÃ©cution)

### Kafka

**Lister les topics :**

```bash
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

**Voir le Consumer Group Lag :**

```bash
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group spark-streaming-group
```

### MongoDB

**AccÃ©der au shell :**

```bash
docker exec -it mongodb mongosh -u root -p rootpassword
```

**Compter les documents :**

```javascript
use github
db.issues.countDocuments()
```

---

## ğŸ”Œ API Endpoints (Streamlit)

| Route      | Description                   |
|------------|-------------------------------|
| `/`        | Page principale avec statistiques |
| `/predict` | Interface de prÃ©diction       |
| `/data`    | Exploration des donnÃ©es       |

---

## ğŸ”§ Troubleshooting

<details>
<summary><b>âŒ Kafka ne dÃ©marre pas</b></summary>

```bash
# VÃ©rifier les logs
docker logs kafka

# RedÃ©marrer Zookeeper puis Kafka
docker compose restart zookeeper
docker compose restart kafka
```

</details>

<details>
<summary><b>âŒ Spark job Ã©choue</b></summary>

```bash
# VÃ©rifier les logs du master
docker logs spark-master

# VÃ©rifier la mÃ©moire disponible
docker stats

# Augmenter la mÃ©moire dans submit.sh
# --conf spark.executor.memory=4g
```

</details>

<details>
<summary><b>âŒ MongoDB connection refused</b></summary>

```bash
# VÃ©rifier que MongoDB est running
docker compose ps mongodb

# Tester la connexion
docker exec -it mongodb mongosh -u root -p rootpassword --eval "db.stats()"
```

</details>

<details>
<summary><b>âŒ Dashboard Streamlit ne charge pas</b></summary>

```bash
# VÃ©rifier les logs
docker logs train-data-audit

# Reconstruire l'image
docker compose up -d --build train-viz
```

</details>

---

## ğŸ“ˆ Roadmap

- [ ] Ajouter support multi-repos
- [ ] ImplÃ©menter alerting (Slack/Email)
- [ ] DÃ©ploiement Kubernetes
- [ ] API REST pour les prÃ©dictions
- [ ] Tests unitaires et intÃ©gration
- [ ] CI/CD avec GitHub Actions

---

## ğŸ‘¥ Contributeurs

| Nom              | RÃ´le                   |
|------------------|------------------------|
| Yahya BAHLOUL    | Etudiant               |
| Zakaria BOUGAYOU | Etudiant               |

---

## ğŸ™ Remerciements

- [Apache Spark](https://spark.apache.org/)
- [Apache Kafka](https://kafka.apache.org/)
- [MongoDB](https://www.mongodb.com/)
- [MLflow](https://mlflow.org/)
- [Streamlit](https://streamlit.io/)

---

<p align="center">
  <b>â­ Si ce projet vous aide, n'hÃ©sitez pas Ã  lui donner une Ã©toile !</b>
</p>